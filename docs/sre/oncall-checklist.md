# âœ… Checklist d'Astreinte On-Call

Ce document sert de rÃ©fÃ©rence opÃ©rationnelle pour toute personne prenant une garde dâ€™astreinte. Il vise Ã  garantir une prise de poste efficace, une rÃ©ponse rapide aux incidents, et une passation claire. Cette checklist doit Ãªtre suivie **Ã  chaque dÃ©but et fin de garde**, et sert Ã©galement de trace en cas d'incident majeur.

---

## ğŸ•˜ Avant la prise de garde

### ğŸ” AccÃ¨s & PrÃ©paration
- [ ] AccÃ¨s VPN/bastion fonctionnel âœ… TestÃ© manuellement
- [ ] AccÃ¨s aux consoles cloud / outils internes (Kubernetes, CI/CD, monitoring...) âœ… VÃ©rifiÃ© avec un collÃ¨gue si doute
- [ ] AccÃ¨s Ã  Opsgenie (ou autre outil d'alerte) validÃ© âœ… Notifications push activÃ©es
- [ ] VÃ©rification des droits nÃ©cessaires (read/write sur les environnements concernÃ©s) âœ… Essai sur une ressource test
- [ ] Connexion testÃ©e aux outils CLI (`kubectl`, `terraform`, `vault`, `gh`, etc.) âœ… Contexte Ã  jour et authentification OK

### ğŸ§° Environnement local prÃªt
- [ ] Terminal configurÃ© (alias, contexte K8s, profils cloud)
- [ ] Dashboards Grafana ouverts en favoris (infrastructure, app critique, DB, etc.)
- [ ] Runbooks accessibles (via Notion, Confluence ou repo clonÃ© localement)
- [ ] Bloc-notes / markdown pour journaliser chaque action pendant la garde

### ğŸ¤ Handoff avec l'on-call prÃ©cÃ©dent
- [ ] Points chauds ou incidents en cours notÃ©s dans le journal
- [ ] DÃ©ploiements prÃ©vus, maintenances planifiÃ©es ou Ã©vÃ©nements sensibles mentionnÃ©s
- [ ] Alertes rÃ©currentes ou flaky connues (ex : CPU spike nocturne sur pod X)
- [ ] VÃ©rification du statut du dernier incident clos (correctif validÃ© ou non)

---

## ğŸš¨ En cas d'incident

### ğŸ” RÃ©action immÃ©diate
- [ ] Identifier la sÃ©vÃ©ritÃ© (S1 : critique, S2 : impact utilisateur, S3 : bruit)
- [ ] VÃ©rifier que lâ€™alerte est lÃ©gitime (bruit, duplication, ou rÃ©el problÃ¨me)
- [ ] Se connecter Ã  l'environnement concernÃ© (cluster, VM, pipeline, etc.)
- [ ] Suivre les runbooks dÃ¨s que possible (ne pas improviser sans trace)
- [ ] Ã‰viter tout changement irrÃ©versible sans appel Ã  un collÃ¨gue si possible

### ğŸ’¬ Communication
- [ ] Annoncer lâ€™incident dans le canal dÃ©diÃ© #incident-active (Slack, Teamsâ€¦)
- [ ] Utiliser la structure "QUI / QUOI / QUAND / PROCHAIN PAS"
- [ ] Taguer le rÃ´le dâ€™escalade ou le secondary-oncall si besoin
- [ ] Mettre Ã  jour un thread dâ€™incident avec les timestamps, actions et rollback Ã©ventuel

### ğŸ§© Action
- [ ] Stabiliser le systÃ¨me (relancer, redÃ©marrer, isoler le problÃ¨me)
- [ ] RÃ©duire lâ€™impact utilisateur (dÃ©sactivation temporaire de feature, trafic coupÃ© vers un pod, etc.)
- [ ] Restaurer les services critiques (base de donnÃ©es, API principales, CI/CD)
- [ ] DÃ©clencher un fallback si nÃ©cessaire (systÃ¨me de secours, replica, cacheâ€¦)

---

## ğŸ§¾ Fin de garde

### ğŸ“ Journal de garde
- [ ] RÃ©capitulatif des incidents rencontrÃ©s (mÃªme mineurs)
- [ ] Actions rÃ©alisÃ©es + liens vers logs / commits / tickets JIRA/GitHub
- [ ] DifficultÃ©s techniques rencontrÃ©es (mÃªme si rÃ©solues Ã  chaud)
- [ ] Retour subjectif : fatigue, charge, suggestions dâ€™amÃ©lioration

### ğŸ“¤ Handoff vers le prochain on-call
- [ ] ProblÃ¨mes non rÃ©solus clairement identifiÃ©s et escaladÃ©s
- [ ] Runbooks Ã  mettre Ã  jour signalÃ©s (et crÃ©Ã©s si besoin)
- [ ] Suggestions dâ€™automatisation ou dâ€™alerte Ã  optimiser listÃ©es
- [ ] Copie du journal envoyÃ©e Ã  lâ€™Ã©quipe SRE ou sauvegardÃ©e dans lâ€™espace dÃ©diÃ©

---

## ğŸ§  Rappel : lâ€™astreinte est une mission de soin
Ce que tu fais ici a de lâ€™impact. Tu protÃ¨ges la continuitÃ© dâ€™un systÃ¨me vivant.
Tu nâ€™es pas seul.e. Tu nâ€™as pas Ã  tout rÃ©parer. Mais tu es le premier bouclier.

> â€œStabilise. Informe. Transmets.â€

---

## ğŸ“Œ Ressources utiles (Ã  adapter selon ton contexte)

- Runbooks : `docs/runbooks/`
- AccÃ¨s rapide Grafana : `https://grafana.example.com`
- Portail Opsgenie : `https://app.opsgenie.com/`
- Bastion SSH : `bastion.company.net`
- Journal de garde modÃ¨le : `templates/oncall-log.md`
- Escalade manager : `+33 6 xx xx xx xx` / `escalade@example.com`

---

> Cette checklist est Ã©volutive. Si une Ã©tape manque ou peut Ãªtre amÃ©liorÃ©e, propose un patch ou une issue.